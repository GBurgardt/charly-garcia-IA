{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-shMc1LBIWjQ",
        "outputId": "352dac6e-0867-451a-8add-614d1530443a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21.74s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip -q install datasets tiktoken openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJagDsTsIn9z"
      },
      "source": [
        "# Fine Tuning OpenAI GPT-3.5-turbo\n",
        "\n",
        "A lot taken from:\n",
        "https://github.com/openai/openai-cookbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9pjgQN3X8uL"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be8iGakrIlZz"
      },
      "source": [
        "## Prepare your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQuGMNYRLYzi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHXnJMQtLcpL"
      },
      "outputs": [],
      "source": [
        "# I am picking one file here but you would probably want to do a lot more for a proper model\n",
        "data_path = \"./fine_tuning_data.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htywc4ELLhJr"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    json_dataset = [json.loads(line) for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeGw1dmhP6E2",
        "outputId": "28c5c096-42fc-42fb-d53a-0cd45f21fb1e"
      },
      "outputs": [],
      "source": [
        "json_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcNXnXCCQCRu"
      },
      "outputs": [],
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3NDk1XTLkHP",
        "outputId": "6ada7306-2625-47e9-80c5-3d8f8cdfe3c6"
      },
      "outputs": [],
      "source": [
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moho_aWELkL2",
        "outputId": "d8e1df78-b3fe-4829-ba1e-08c6a5d7c129"
      },
      "outputs": [],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPC_AxVWLq1S"
      },
      "outputs": [],
      "source": [
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI1sbe6zLrp3",
        "outputId": "f9896417-e6fb-493d-812e-08c341023bcd"
      },
      "outputs": [],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk2BTW9tWVEm",
        "outputId": "fd6765db-c71a-4731-bd0a-cabc9500242b"
      },
      "outputs": [],
      "source": [
        "dataset[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DomOc2YzL9xc",
        "outputId": "bc78b623-bb18-4725-d019-acde22ff7d89"
      },
      "outputs": [],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "print(\"See pricing page to estimate total costs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nqR5W_NWqmF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for conversation in conversations:\n",
        "            json_line = json.dumps(conversation)\n",
        "            file.write(json_line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvci7_E3WvgR"
      },
      "outputs": [],
      "source": [
        "# train dataset\n",
        "save_to_jsonl(dataset, '/content/samantha_tasks_train.jsonl')\n",
        "\n",
        "# train dataset\n",
        "save_to_jsonl(dataset[10:15], '/content/samantha_tasks_validation.jsonl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdsf_iSZIz1B"
      },
      "source": [
        "## Upload your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLgciBDyI1K9"
      },
      "outputs": [],
      "source": [
        "# curl -https://api.openai.com/v1/files \\\n",
        "#   -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
        "#   -F \"purpose=fine-tune\" \\\n",
        "#   -F \"file=@path_to_your_file\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNCT7UmxXJJp"
      },
      "outputs": [],
      "source": [
        "training_file_name = '/content/samantha_tasks_train.jsonl'\n",
        "validation_file_name = '/content/samantha_tasks_validation.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOFng4CLI5zV",
        "outputId": "20fe53ec-3b05-43ca-cbf9-85ad4913c502"
      },
      "outputs": [],
      "source": [
        "training_response = openai.File.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response[\"id\"]\n",
        "\n",
        "validation_response = openai.File.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file_id = validation_response[\"id\"]\n",
        "\n",
        "print(\"Training file id:\", training_file_id)\n",
        "print(\"Validation file id:\", validation_file_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3THl05MI6is"
      },
      "source": [
        "## Create a Fine Tuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpqcS1G_I82-"
      },
      "outputs": [],
      "source": [
        "# curl https://api.openai.com/v1/fine_tuning/jobs \\\n",
        "# -H \"Content-Type: application/json\" \\\n",
        "# -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
        "# -d '{\n",
        "#   \"training_file\": \"TRAINING_FILE_ID\",\n",
        "#   \"model\": \"gpt-3.5-turbo-0613\",\n",
        "# }'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_4tg0agYxwL"
      },
      "outputs": [],
      "source": [
        "suffix_name = \"samantha-test\"\n",
        "\n",
        "\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "\n",
        "job_id = response[\"id\"]\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tyx24DHY2Pr"
      },
      "outputs": [],
      "source": [
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deleFEzCY7sI",
        "outputId": "22b39e67-abdf-49f3-b921-df6d7988452d"
      },
      "outputs": [],
      "source": [
        "response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n",
        "\n",
        "events = response[\"data\"]\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event[\"message\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YettixpjZBaQ"
      },
      "outputs": [],
      "source": [
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "fine_tuned_model_id = response[\"fine_tuned_model\"]\n",
        "\n",
        "print(response)\n",
        "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx2BgYMwZRzr"
      },
      "source": [
        "## Generating using the new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFWWJFBfZOdt",
        "outputId": "1258cba5-beed-4b92-8ad4-d000a4e714f9"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_messages = []\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "user_message = \"How are you today Samantha\"\n",
        "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "print(test_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAbo1eK3eK6S",
        "outputId": "68fd7412-505e-476c-c6c4-43741afd131a"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsgorbF9eXI2"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHDrSlUXecKF",
        "outputId": "a66eab8e-4acf-496d-e5f7-d0ae36d447e1"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo', messages=test_messages, temperature=0, max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbOdto65tjOf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
